# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11HX88Sv7H_rt2ElQ6nTBHNdMofyTizCa
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow_hub

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import matplotlib.pyplot as plt
import numpy as np
import logging
logger = tf.get_logger()
logger.setLevel(logging.ERROR)
import matplotlib.pylab as plt
import tensorflow_hub as hub
import tensorflow_datasets as tfds
from tensorflow.keras import layers
import numpy as np
import cv2
import pandas as pd
import PIL.Image as Image
import os
import matplotlib.pylab as plt
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

IMAGE_RES = 360
URL = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2"
feature_extractor = hub.KerasLayer(URL,
                                   input_shape=(IMAGE_RES, IMAGE_RES,3))

emotions_labels_dict = {
    'surprise': 0,
    'joy': 1,
    'anger': 2,
    'neutral' : 3,
    'sadness': 4,
}

X = []
y = []

file_labels_dict = {}
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Project II/Spectograms'):
    for filename in filenames:
        label = filename.split('_')[0]  # Extract the first word before '_'
        file_labels_dict[filename] = label

# Load image data
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Project II/Spectograms'):
    for filename in filenames:
        path = os.path.join(dirname, filename)
        img = cv2.imread(path)
        resized_img = cv2.resize(img, (224, 224))
        X.append(resized_img)
        label = file_labels_dict[filename]
        y.append(emotions_labels_dict[label])
print('Dataset is Loaded!')

y = [emotions_labels_dict.get(a) if emotions_labels_dict.get(a) else a for a in y]

import matplotlib.pyplot as plt
import numpy as np

# Create a dictionary to count the instances of each emotion
emotion_counts = {}
for emotion in emotions_labels_dict:
    emotion_counts[emotion] = y.count(emotions_labels_dict[emotion])

# Plot a bar chart of the emotion counts
fig, ax = plt.subplots()
ax.bar(emotion_counts.keys(), emotion_counts.values())

# Set the chart title and axis labels
ax.set_xlabel('Emotion')
ax.set_ylabel('Frequency')

# Rotate the x-axis labels to avoid overlapping
plt.xticks(rotation=45, ha='right')

# Save the plot as a PNG image
plt.savefig('emotion_counts.png')

# Display the chart
plt.show()

x = np.array(X)
y = np.array(y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, train_size = 0.8, random_state=0)

IMAGE_SHAPE = (224, 224)
IMAGE_SHAPE+(3,)

x0_resized = cv2.resize(x[333], IMAGE_SHAPE)
x1_resized = cv2.resize(x[1], IMAGE_SHAPE)
x2_resized = cv2.resize(X[2], IMAGE_SHAPE)

plt.axis('off')
plt.imshow(x[333])

y[333]

classifier = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", input_shape=IMAGE_SHAPE+(3,))
])
predicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))
predicted = np.argmax(predicted, axis=1)
predicted

feature_extractor_model = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"

pretrained_model_without_top_layer = hub.KerasLayer(
    feature_extractor_model, input_shape=(224, 224, 3), trainable=True)
num_of_classes = 5

model = tf.keras.Sequential([
  pretrained_model_without_top_layer,
  tf.keras.layers.Dense(num_of_classes)
])

model.summary()

model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy'])

early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)
checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath="best_model.h5", save_best_only=True)

history = model.fit(X_train, y_train, epochs=7, callbacks=[early_stopping_cb])

score = model.evaluate(X_test, y_test)

print('Test loss:', score[0])
print('Test accuracy:', score[1])

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

z = model.predict(X_test, batch_size= None)
z = np.argmax(z, axis=1)
z

from sklearn.metrics import classification_report
from tabulate import tabulate

class_names = ['surprise', 'joy', 'anger', 'neutral', 'sadness']
report = classification_report(y_test, z, target_names=class_names)

report

# Convert the classification report to a table
table = tabulate([x.split() for x in report.split('\n')[2:-5]])

# Print the table
print(table)

from sklearn.metrics import confusion_matrix

#Generate the confusion matrix
cf_matrix = confusion_matrix(y_test, z)

print(cf_matrix)

import seaborn as sns

fig, ax = plt.subplots(figsize=(8, 8))
ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', ax=ax, fmt='.0f')

ax.set_title('Confusion MAtrix');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['Surprise', 'Joy', 'Anger', 'Neutral', 'Sadness'])
ax.yaxis.set_ticklabels(['Surprise', 'Joy', 'Anger', 'Neutral', 'Sadness'])

## Display the visualization of the Confusion Matrix.
#plt.show()
plt.savefig('confusion matrix.png', dpi = 600, bbox_inches='tight')

X = []
y = []
file_labels_dict = {}
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Project II/test'):
    for filename in filenames:
        label = filename.split('_')[0]  # Extract the first word before '_'
        file_labels_dict[filename] = label

# Load image data
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Project II/test'):
    for filename in filenames:
        path = os.path.join(dirname, filename)
        img = cv2.imread(path)
        resized_img = cv2.resize(img, (224, 224))
        label = file_labels_dict[filename]
        y.append(emotions_labels_dict[label])
        X.append(resized_img)
print('Dataset is Loaded!')

predicted = model.predict(np.array(X))
predicted = np.argmax(predicted, axis=1)

np.array(y)

classification_report(y, predicted, target_names =class_names)

#Generate the confusion matrix
cf_matrix = confusion_matrix(y, predicted)

print(cf_matrix)

import seaborn as sns

fig, ax = plt.subplots(figsize=(8, 8))
ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', ax=ax, fmt='.0f')

ax.set_title('Confusion MAtrix');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['Surprise', 'Joy', 'Anger', 'Neutral', 'Sadness'])
ax.yaxis.set_ticklabels(['Surprise', 'Joy', 'Anger', 'Neutral', 'Sadness'])

## Display the visualization of the Confusion Matrix.
#plt.show()
plt.savefig('confusion matrix2.png', dpi = 600, bbox_inches='tight')

import matplotlib.pyplot as plt
import numpy as np

# Create a dictionary to count the instances of each emotion
emotion_counts = {}
for emotion in emotions_labels_dict:
    emotion_counts[emotion] = y.count(emotions_labels_dict[emotion])

# Plot a bar chart of the emotion counts
fig, ax = plt.subplots()
ax.bar(emotion_counts.keys(), emotion_counts.values())

# Set the chart title and axis labels
ax.set_xlabel('Emotion')
ax.set_ylabel('Frequency')

# Rotate the x-axis labels to avoid overlapping
plt.xticks(rotation=45, ha='right')

# Save the plot as a PNG image
plt.savefig('test_emotion_counts.png')

# Display the chart
plt.show()

model.save('finalmodel.h5')
model.save_weights('finalmodelWeights')
model.save_weights('finalmodelWeights.h5')

from pickle import dump

dump(model, open('model.pkl', 'wb'))

Emotions_saved_model = "Emotions_saved_model"

import tensorflow as tf

tf.saved_model.save(model, Emotions_saved_model)

# Commented out IPython magic to ensure Python compatibility.
# %%bash -s $Emotions_saved_model
# saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default

loaded = tf.saved_model.load(Emotions_saved_model)

loaded

print(list(loaded.signatures.keys()))
infer = loaded.signatures["serving_default"]
print(infer.structured_input_signature)
print(infer.structured_outputs)

converter = tf.lite.TFLiteConverter.from_saved_model(Emotions_saved_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
tflite_model_file = 'image_converted_model.tflite'

with open(tflite_model_file, "wb") as f:
  f.write(tflite_model)

predicted = model.predict(np.array([x0_resized, x1_resized, x2_resized]))
predicted = np.argmax(predicted, axis=1)
predicted

import numpy as np
import matplotlib.pyplot as plt

# Define the data
categories = ['surprise', 'joy', 'anger', 'neutral', 'sadness', 'total']
f1_scores = [94, 93, 30, 90, 61, 74]
supports = [50, 60, 61, 54, 60, 285]


# Set the positions for the bars
x_pos = np.arange(len(categories))

# Set the width of the bars
width = 0.35

# Create a figure and axis
fig, ax = plt.subplots()

# Create the bar plot for F1-score (green)
ax.bar(x_pos, f1_scores, width, color='g', alpha=0.7, label='F1-score')

# Create the bar plot for support (yellow)
ax.bar(x_pos + width, supports, width, color='y', alpha=0.7, label='Support')

# Set the x-axis tick positions and labels
ax.set_xticks(x_pos + width / 2)
ax.set_xticklabels(categories)

# Set the labels and title
ax.set_title('Model Results on External Evaluation')

# Set the legend
ax.legend()

# Save the plot as a PNG image
plt.savefig('model_results.png')

# Display the plot
plt.show()

import os
import cv2
import matplotlib.pyplot as plt

# Define the directory path
directory_path = '/content/drive/MyDrive/Project II/test'

# Create a dictionary to store the count of files for each emotion
emotion_count = {}

# Iterate through the directory and count the files
for dirname, _, filenames in os.walk(directory_path):
    for filename in filenames:
        label = filename.split('_')[0]  # Extract the first word before '_'
        emotion_count[label] = emotion_count.get(label, 0) + 1

# Extract the emotion labels and their respective counts
emotions = list(emotion_count.keys())
counts = list(emotion_count.values())

# Calculate the percentage for each emotion
total_files = sum(counts)
percentages = [(count / total_files) * 100 for count in counts]

# Create a pie chart
plt.figure(figsize=(8, 6))
plt.pie(percentages, labels=emotions, autopct='%1.1f%%', startangle=90)

# Set the title
plt.title('Distribution of Emotions')

# Save the chart as an image
plt.savefig('emotion_distribution1.png')

# Display the chart
plt.show()
